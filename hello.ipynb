{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86966ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Verify X and y and train model robustly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ca0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\hiyan\\OneDrive\\Desktop\\Projects\\deepdata\\flood_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e0d4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_mapping = {'low_risk': 1, 'medium_risk': 2, 'high_risk': 3, 'low_lying_flooding': 4}\n",
    "df['risk_score'] = df['risk_labels'].map(risk_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fe9b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fill, hazard_index non-null: 2802\n",
      "Filled missing elevation_m with median = 25.130000000000003\n",
      "Recomputed hazard_index; non-null: 2963\n",
      "Created 'risk_auto' target from hazard_index tertiles. Non-null: 2963\n",
      "\n",
      "After changes, target availability:\n",
      "risk_labels -> not present\n",
      "risk_score -> 0\n",
      "risk_auto -> 2963\n"
     ]
    }
   ],
   "source": [
    "# Optional: recreate a fallback target by filling inputs and recomputing hazard_index\n",
    "import pandas as pd\n",
    "\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"df is not defined. Run the CSV load cell first.\")\n",
    "\n",
    "print('Before fill, hazard_index non-null:', df['hazard_index'].notna().sum() if 'hazard_index' in df.columns else 'no hazard_index')\n",
    "\n",
    "# Fill elevation and rainfall with medians if present\n",
    "for col in ['elevation_m','historical_rainfall_intensity_mm_hr']:\n",
    "    if col in df.columns:\n",
    "        nnull = df[col].notna().sum()\n",
    "        if nnull < len(df):\n",
    "            med = df[col].median(skipna=True)\n",
    "            df[col] = df[col].fillna(med)\n",
    "            print(f\"Filled missing {col} with median = {med}\")\n",
    "\n",
    "if 'elevation_m' in df.columns and 'historical_rainfall_intensity_mm_hr' in df.columns:\n",
    "    df['hazard_index'] = df['elevation_m'] * df['historical_rainfall_intensity_mm_hr']\n",
    "    print('Recomputed hazard_index; non-null:', df['hazard_index'].notna().sum())\n",
    "\n",
    "# Create fallback categorical target from hazard_index tertiles if risk_labels missing\n",
    "if 'risk_labels' not in df.columns:\n",
    "    if 'hazard_index' in df.columns and df['hazard_index'].notna().sum() > 0:\n",
    "        df['risk_auto'] = pd.qcut(df['hazard_index'].rank(method='first'), q=3, labels=['low_risk','medium_risk','high_risk'])\n",
    "        print(\"Created 'risk_auto' target from hazard_index tertiles. Non-null:\", df['risk_auto'].notna().sum())\n",
    "    else:\n",
    "        print(\"Cannot create fallback target: no usable hazard_index\")\n",
    "\n",
    "print('\\nAfter changes, target availability:')\n",
    "for t in ['risk_labels','risk_score','risk_auto']:\n",
    "    print(t, '->', (df[t].notna().sum() if t in df.columns else 'not present'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "810908dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_labels: present=False, non-null=0\n",
      "risk_score: present=True, non-null=0\n",
      "risk_auto: present=True, non-null=2963\n",
      "Selected target: risk_auto\n",
      "Samples available for training after mask: 2963\n",
      "X_encoded shape: (2963, 3318)\n",
      "y distribution:\n",
      " risk_auto\n",
      "low_risk       988\n",
      "high_risk      988\n",
      "medium_risk    987\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.99      1.00      1.00       198\n",
      "    low_risk       0.99      1.00      0.99       198\n",
      " medium_risk       1.00      0.98      0.99       197\n",
      "\n",
      "    accuracy                           0.99       593\n",
      "   macro avg       0.99      0.99      0.99       593\n",
      "weighted avg       0.99      0.99      0.99       593\n",
      "\n",
      "\n",
      "Top 10 feature importances:\n",
      " hazard_index                           0.326372\n",
      "elevation_m                            0.192974\n",
      "historical_rainfall_intensity_mm_hr    0.037630\n",
      "longitude                              0.021636\n",
      "latitude                               0.021220\n",
      "storm_drain_proximity_m                0.019416\n",
      "drainage_density_km_per_km2            0.017947\n",
      "soil_group_B                           0.004349\n",
      "dem_source_Copernicus_GLO-30_v2023     0.004288\n",
      "storm_drain_type_Manhole               0.004018\n",
      "dtype: float64\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.99      1.00      1.00       198\n",
      "    low_risk       0.99      1.00      0.99       198\n",
      " medium_risk       1.00      0.98      0.99       197\n",
      "\n",
      "    accuracy                           0.99       593\n",
      "   macro avg       0.99      0.99      0.99       593\n",
      "weighted avg       0.99      0.99      0.99       593\n",
      "\n",
      "\n",
      "Top 10 feature importances:\n",
      " hazard_index                           0.326372\n",
      "elevation_m                            0.192974\n",
      "historical_rainfall_intensity_mm_hr    0.037630\n",
      "longitude                              0.021636\n",
      "latitude                               0.021220\n",
      "storm_drain_proximity_m                0.019416\n",
      "drainage_density_km_per_km2            0.017947\n",
      "soil_group_B                           0.004349\n",
      "dem_source_Copernicus_GLO-30_v2023     0.004288\n",
      "storm_drain_type_Manhole               0.004018\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Robust training cell: uses available target and trains only if samples exist\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"df is not defined. Run the CSV load cell first.\")\n",
    "\n",
    "# Show current target availability\n",
    "for t in ['risk_labels','risk_score','risk_auto']:\n",
    "    print(f\"{t}: present={t in df.columns}, non-null={(df[t].notna().sum() if t in df.columns else 0)}\")\n",
    "\n",
    "# Repair risk_labels if it's multi-label (pipe-separated) by choosing the first meaningful label\n",
    "if 'risk_labels' in df.columns:\n",
    "    # Convert empty strings to NaN\n",
    "    df['risk_labels'] = df['risk_labels'].replace({'': pd.NA})\n",
    "    # If entries contain pipes, pick the first token (most-specific may be first)\n",
    "    def pick_label(val):\n",
    "        if pd.isna(val):\n",
    "            return val\n",
    "        if '|' in str(val):\n",
    "            # preference map: map known keywords to canonical classes\n",
    "            parts = [p.strip() for p in str(val).split('|') if p.strip()]\n",
    "            # mapping examples\n",
    "            for pref in ['extreme_rain_history','ponding_hotspot','low_lying','event','sparse_drainage']:\n",
    "                for p in parts:\n",
    "                    if pref in p:\n",
    "                        return pref\n",
    "            # otherwise return first part\n",
    "            return parts[0]\n",
    "        return val\n",
    "    df['risk_labels'] = df['risk_labels'].apply(pick_label)\n",
    "    print('After normalizing, risk_labels non-null:', df['risk_labels'].notna().sum())\n",
    "\n",
    "# If no usable target, try to build risk_auto from hazard_index\n",
    "if not any(c in df.columns and df[c].notna().sum() > 0 for c in ['risk_labels','risk_score','risk_auto']):\n",
    "    print('No existing labeled target found; attempting to build `risk_auto` from inputs...')\n",
    "    # Fill numeric inputs with medians if missing\n",
    "    for col in ['elevation_m','historical_rainfall_intensity_mm_hr']:\n",
    "        if col in df.columns:\n",
    "            med = df[col].median(skipna=True)\n",
    "            df[col] = df[col].fillna(med)\n",
    "            print(f'Filled {col} with median={med}')\n",
    "    if 'elevation_m' in df.columns and 'historical_rainfall_intensity_mm_hr' in df.columns:\n",
    "        df['hazard_index'] = df['elevation_m'] * df['historical_rainfall_intensity_mm_hr']\n",
    "        # create tertiles\n",
    "        df['risk_auto'] = pd.qcut(df['hazard_index'].rank(method='first'), q=3, labels=['low_risk','medium_risk','high_risk'])\n",
    "        print('Created risk_auto from hazard_index; non-null:', df['risk_auto'].notna().sum())\n",
    "\n",
    "# Pick target\n",
    "if 'risk_labels' in df.columns and df['risk_labels'].notna().sum() > 0:\n",
    "    target_col = 'risk_labels'\n",
    "elif 'risk_score' in df.columns and df['risk_score'].notna().sum() > 0:\n",
    "    target_col = 'risk_score'\n",
    "elif 'risk_auto' in df.columns and df['risk_auto'].notna().sum() > 0:\n",
    "    target_col = 'risk_auto'\n",
    "else:\n",
    "    raise KeyError('No target column available after repair attempts. Inspect the dataset.')\n",
    "\n",
    "print('Selected target:', target_col)\n",
    "\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[c for c in ['risk_labels','risk_score','risk_auto'] if c in df.columns])\n",
    "\n",
    "# Drop missing target rows\n",
    "mask = y.notna()\n",
    "X = X.loc[mask].copy()\n",
    "y = y.loc[mask].copy()\n",
    "print('Samples available for training after mask:', len(y))\n",
    "if len(y) == 0:\n",
    "    raise ValueError('No samples after dropping missing target even after repair attempts')\n",
    "\n",
    "# If numeric risk_score, bin into categories for classification\n",
    "if target_col == 'risk_score' and y.dtype.kind in 'if':\n",
    "    y = pd.qcut(y.rank(method='first'), q=3, labels=['low_risk','medium_risk','high_risk'])\n",
    "    print('Binned numeric risk_score into categorical target')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "if len(categorical_cols) > 0:\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "else:\n",
    "    X_encoded = X.copy()\n",
    "\n",
    "# Convert remaining object dtypes to numeric codes\n",
    "for col in X_encoded.columns:\n",
    "    if X_encoded[col].dtype == 'O':\n",
    "        X_encoded[col] = X_encoded[col].astype('category').cat.codes\n",
    "\n",
    "# Decide stratify argument safely\n",
    "stratify_arg = None\n",
    "if y.nunique() >= 2:\n",
    "    vc = y.value_counts()\n",
    "    if (vc >= 2).all():\n",
    "        stratify_arg = y\n",
    "    else:\n",
    "        print('Not stratifying: at least one class has <2 samples')\n",
    "\n",
    "print('X_encoded shape:', X_encoded.shape)\n",
    "print('y distribution:\\n', y.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=stratify_arg)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "fi = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "print('\\nTop 10 feature importances:\\n', fi.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a0a9bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive dashboard saved as urban_flood_risk_dashboard.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "# Determine which target column to use for visualization\n",
    "if 'risk_labels' in df.columns and df['risk_labels'].notna().sum() > 0:\n",
    "    viz_col = 'risk_labels'\n",
    "elif 'risk_auto' in df.columns and df['risk_auto'].notna().sum() > 0:\n",
    "    viz_col = 'risk_auto'\n",
    "elif 'risk_score' in df.columns and df['risk_score'].notna().sum() > 0:\n",
    "    viz_col = 'risk_score'\n",
    "else:\n",
    "    viz_col = None\n",
    "    print('Warning: no risk label column available; map will use gray markers')\n",
    "\n",
    "# Create a base map centered at the average location of the data points\n",
    "map_center = [df['latitude'].mean(), df['longitude'].mean()]\n",
    "flood_map = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Define a color scheme for the risk labels\n",
    "color_map = {\n",
    "    'low_risk': 'green',\n",
    "    'medium_risk': 'orange',\n",
    "    'high_risk': 'red',\n",
    "    'low_lying_flooding': 'darkred'\n",
    "}\n",
    "\n",
    "# Add markers for each data point safely\n",
    "for index, row in df.iterrows():\n",
    "    label = None if viz_col is None else row.get(viz_col, None)\n",
    "    # If label is numeric risk_score, bin it for colors\n",
    "    if viz_col == 'risk_score' and label is not None:\n",
    "        try:\n",
    "            # create a temporary binning\n",
    "            if float(label) <= df['risk_score'].quantile(0.33):\n",
    "                label = 'low_risk'\n",
    "            elif float(label) <= df['risk_score'].quantile(0.66):\n",
    "                label = 'medium_risk'\n",
    "            else:\n",
    "                label = 'high_risk'\n",
    "        except Exception:\n",
    "            label = None\n",
    "\n",
    "    risk_color = color_map.get(label, 'gray')\n",
    "\n",
    "    # Safe numeric formatting with fallbacks\n",
    "    def fmt_float(val):\n",
    "        try:\n",
    "            return f\"{float(val):.2f}\"\n",
    "        except Exception:\n",
    "            return 'N/A'\n",
    "\n",
    "    elevation = fmt_float(row.get('elevation_m', None))\n",
    "    rainfall = fmt_float(row.get('historical_rainfall_intensity_mm_hr', None))\n",
    "    drainage = fmt_float(row.get('drainage_density_km_per_km2', None))\n",
    "    land_use = row.get('land_use', 'N/A')\n",
    "\n",
    "    popup_text = (\n",
    "        f\"<b>Risk:</b> {label if label is not None else 'unknown'}<br>\"\n",
    "        f\"<b>Elevation:</b> {elevation}m<br>\"\n",
    "        f\"<b>Rainfall:</b> {rainfall}mm/hr<br>\"\n",
    "        f\"<b>Drainage Density:</b> {drainage}<br>\"\n",
    "        f\"<b>Land Use:</b> {land_use}\"\n",
    "    )\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        color=risk_color,\n",
    "        fill=True,\n",
    "        fill_color=risk_color,\n",
    "        fill_opacity=0.7,\n",
    "        tooltip=str(label) if label is not None else None,\n",
    "        popup=popup_text\n",
    "    ).add_to(flood_map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "flood_map.save(\"urban_flood_risk_dashboard.html\")\n",
    "print(\"Interactive dashboard saved as urban_flood_risk_dashboard.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c649f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
